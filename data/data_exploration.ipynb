{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  int64  \n",
      " 1   company_name                122130 non-null  object \n",
      " 2   title                       123849 non-null  object \n",
      " 3   description                 123842 non-null  object \n",
      " 4   max_salary                  29793 non-null   float64\n",
      " 5   pay_period                  36073 non-null   object \n",
      " 6   location                    123849 non-null  object \n",
      " 7   company_id                  122132 non-null  float64\n",
      " 8   views                       122160 non-null  float64\n",
      " 9   med_salary                  6280 non-null    float64\n",
      " 10  min_salary                  29793 non-null   float64\n",
      " 11  formatted_work_type         123849 non-null  object \n",
      " 12  applies                     23320 non-null   float64\n",
      " 13  original_listed_time        123849 non-null  float64\n",
      " 14  remote_allowed              15246 non-null   float64\n",
      " 15  job_posting_url             123849 non-null  object \n",
      " 16  application_url             87184 non-null   object \n",
      " 17  application_type            123849 non-null  object \n",
      " 18  expiry                      123849 non-null  float64\n",
      " 19  closed_time                 1073 non-null    float64\n",
      " 20  formatted_experience_level  94440 non-null   object \n",
      " 21  skills_desc                 2439 non-null    object \n",
      " 22  listed_time                 123849 non-null  float64\n",
      " 23  posting_domain              83881 non-null   object \n",
      " 24  sponsored                   123849 non-null  int64  \n",
      " 25  work_type                   123849 non-null  object \n",
      " 26  currency                    36073 non-null   object \n",
      " 27  compensation_type           36073 non-null   object \n",
      " 28  normalized_salary           36073 non-null   float64\n",
      " 29  zip_code                    102977 non-null  float64\n",
      " 30  fips                        96434 non-null   float64\n",
      "dtypes: float64(14), int64(2), object(15)\n",
      "memory usage: 29.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('linkedin_jobs.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  int64  \n",
      " 1   company_name                122130 non-null  object \n",
      " 2   title                       123849 non-null  object \n",
      " 3   description                 123842 non-null  object \n",
      " 4   max_salary                  29793 non-null   float64\n",
      " 5   pay_period                  36073 non-null   object \n",
      " 6   location                    123849 non-null  object \n",
      " 7   company_id                  122132 non-null  float64\n",
      " 8   views                       122160 non-null  float64\n",
      " 9   med_salary                  6280 non-null    float64\n",
      " 10  min_salary                  29793 non-null   float64\n",
      " 11  formatted_work_type         123849 non-null  object \n",
      " 12  applies                     23320 non-null   float64\n",
      " 13  original_listed_time        123849 non-null  float64\n",
      " 14  remote_allowed              15246 non-null   float64\n",
      " 15  job_posting_url             123849 non-null  object \n",
      " 16  application_url             87184 non-null   object \n",
      " 17  application_type            123849 non-null  object \n",
      " 18  expiry                      123849 non-null  float64\n",
      " 19  closed_time                 1073 non-null    float64\n",
      " 20  formatted_experience_level  94440 non-null   object \n",
      " 21  skills_desc                 2439 non-null    object \n",
      " 22  listed_time                 123849 non-null  float64\n",
      " 23  posting_domain              83881 non-null   object \n",
      " 24  sponsored                   123849 non-null  int64  \n",
      " 25  work_type                   123849 non-null  object \n",
      " 26  currency                    36073 non-null   object \n",
      " 27  compensation_type           36073 non-null   object \n",
      " 28  normalized_salary           36073 non-null   float64\n",
      " 29  zip_code                    102977 non-null  float64\n",
      " 30  fips                        96434 non-null   float64\n",
      "dtypes: float64(14), int64(2), object(15)\n",
      "memory usage: 29.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('linkedin_jobs.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_columns = ['title', 'description']\n",
    "df_tfidf = df[tfidf_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        123849 non-null  object\n",
      " 1   description  123842 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values in each column:\n",
      "title          0\n",
      "description    7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNull values in each column:\")\n",
    "print(df_tfidf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_tfidf.dropna(subset=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Service Technician</td>\n",
       "      <td>Looking for HVAC service tech with experience ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "1                  Mental Health Therapist/Counselor   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "4                                 Service Technician   \n",
       "\n",
       "                                         description  \n",
       "0  Job descriptionA leading real estate firm in N...  \n",
       "1  At Aspen Therapy and Wellness , we are committ...  \n",
       "2  The National Exemplar is accepting application...  \n",
       "3  Senior Associate Attorney - Elder Law / Trusts...  \n",
       "4  Looking for HVAC service tech with experience ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSample data:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\62390856.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']\n"
     ]
    }
   ],
   "source": [
    "df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample combined text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Marketing Coordinator | Job descriptionA leadi...\n",
       "1    Mental Health Therapist/Counselor | At Aspen T...\n",
       "2    Assitant Restaurant Manager | The National Exe...\n",
       "3    Senior Elder Law / Trusts and Estates Associat...\n",
       "4     Service Technician | Looking for HVAC service...\n",
       "Name: combined_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sample combined text:\")\n",
    "df_clean['combined_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test lemmatization:\n",
      "Original: Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\n",
      "Processed: marketing coordinator job description coordinate marketing campaign analyze metric work team manage project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        # POS tagging\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        \n",
    "        # Lemmatize with POS\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_tokens = []\n",
    "        for token, tag in pos_tags:\n",
    "            if tag.startswith('VB'):  # Verb\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='v')\n",
    "            elif tag.startswith('NN'):  # Noun\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='n')\n",
    "            elif tag.startswith('JJ'):  # Adjective\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='a')\n",
    "            else:\n",
    "                lem_token = lemmatizer.lemmatize(token)\n",
    "            lemmatized_tokens.append(lem_token)\n",
    "        \n",
    "        return ' '.join(lemmatized_tokens)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Test with the same text\n",
    "test_text = \"Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\"\n",
    "processed = preprocess_text(test_text)\n",
    "\n",
    "print(\"\\nTest lemmatization:\")\n",
    "print(\"Original:\", test_text)\n",
    "print(\"Processed:\", processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\1890915169.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs Processed Text:\n",
      "\n",
      "Original: Marketing Coordinator | Job descriptionA leading real estate firm in New Jersey is seeking an administrative Marketing Coordinator with some experience in graphic design. You will be working closely w ...\n",
      "Processed: marketing coordinator job descriptiona lead real estate firm new jersey seek administrative marketing coordinator experience graphic design work closely fun kind ambitious member sale team dynamic exe ...\n",
      "\n",
      "Original: Mental Health Therapist/Counselor | At Aspen Therapy and Wellness , we are committed to serving clients with best practices to help them with change, improvements and better quality of life. We believ ...\n",
      "Processed: mental health therapist counselor aspen therapy wellness commit serve client best practice help change improvement better quality life believe provide secure supportive environment grow clinician lear ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Original vs Processed Text:\")\n",
    "for orig, proc in zip(df_clean['combined_text'].head(2), df_clean['processed_text'].head(2)):\n",
    "    print(\"\\nOriginal:\", orig[:200], \"...\")\n",
    "    print(\"Processed:\", proc[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TFIDF matrix: (123842, 1000)\n",
      "\n",
      "Number of features: 1000\n",
      "\n",
      "Sample features (first 20):\n",
      "['ability' 'ability work' 'able' 'accept' 'access' 'accommodation'\n",
      " 'accord' 'accordance' 'account' 'accountability' 'accounting' 'accredit'\n",
      " 'accuracy' 'accurate' 'accurately' 'achieve' 'across' 'act' 'action'\n",
      " 'active']\n",
      "\n",
      "Sample document vector (first document):\n",
      "Non-zero terms and their TFIDF scores:\n",
      "marketing: 0.3849\n",
      "design: 0.2246\n",
      "event: 0.1816\n",
      "brand: 0.1785\n",
      "organize: 0.1768\n",
      "coordinator: 0.1630\n",
      "person: 0.1586\n",
      "request: 0.1511\n",
      "fun: 0.1494\n",
      "market: 0.1435\n"
     ]
    }
   ],
   "source": [
    "# Create TFIDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit features to most frequent 1000 terms\n",
    "    min_df=5,          # Ignore terms that appear in less than 5 documents\n",
    "    max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
    "    ngram_range=(1, 2) # Include both unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = tfidf.fit_transform(df_clean['processed_text'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Shape of TFIDF matrix: {tfidf_matrix.shape}\")\n",
    "print(f\"\\nNumber of features: {len(feature_names)}\")\n",
    "print(\"\\nSample features (first 20):\")\n",
    "print(feature_names[:20])\n",
    "\n",
    "# Show sample vector\n",
    "print(\"\\nSample document vector (first document):\")\n",
    "sample_vector = tfidf_matrix[0].toarray()[0]\n",
    "sample_terms = [(term, score) for term, score in zip(feature_names, sample_vector) if score > 0]\n",
    "print(\"Non-zero terms and their TFIDF scores:\")\n",
    "for term, score in sorted(sample_terms, key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{term}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user profiles\n",
    "sample_users = [\n",
    "    {\n",
    "        'skills': [\"Digital Marketing\", \"Brand Management\", \"Social Media\", \"Graphic Design\"],\n",
    "        'experience': 5.5,\n",
    "        'education': [\"bachelor, Marketing University\", \"master, Digital Marketing Institute\"],\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'skills': [\"Python\", \"FastAPI\", \"SQL\", \"Machine Learning\"],\n",
    "        'experience': 3.0,\n",
    "        'education': [\"bachelor, Computer Science University\"],\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sample job postings\n",
    "sample_jobs = [\n",
    "    {\n",
    "        'title': \"Senior Marketing Manager\",\n",
    "        'description': \"Looking for an experienced marketing professional to lead our digital marketing initiatives.\",\n",
    "        'required_skills': [\"Digital Marketing\", \"Brand Management\", \"Team Leadership\"],\n",
    "        'required_experience': 5.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'title': \"Python Developer\",\n",
    "        'description': \"Seeking a Python developer with experience in web frameworks and machine learning.\",\n",
    "        'required_skills': [\"Python\", \"FastAPI\", \"SQL\"],\n",
    "        'required_experience': 2.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "# Prepare text for vectorization\n",
    "def prepare_user_text(user):\n",
    "    text = ' '.join(user['skills'])\n",
    "    text += ' ' + ' '.join([edu.split(',')[0] for edu in user['education']])  # Add education levels\n",
    "    return text\n",
    "\n",
    "def prepare_job_text(job):\n",
    "    text = job['title'] + ' ' + job['description']\n",
    "    text += ' ' + ' '.join(job['required_skills'])\n",
    "    text += ' ' + job['required_education']\n",
    "    return text\n",
    "\n",
    "# Preprocess and vectorize\n",
    "user_texts = [preprocess_text(prepare_user_text(u)) for u in sample_users]\n",
    "job_texts = [preprocess_text(prepare_job_text(j)) for j in sample_jobs]\n",
    "\n",
    "# Transform texts to TFIDF vectors\n",
    "user_vectors = tfidf.transform(user_texts)\n",
    "job_vectors = tfidf.transform(job_texts)\n",
    "\n",
    "# Calculate similarity\n",
    "similarities = cosine_similarity(user_vectors, job_vectors)\n",
    "\n",
    "# Print results\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    user_similarities = similarities[i]\n",
    "    top_matches = sorted(enumerate(user_similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Similarity Score: {score:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.7379\n",
      "  TFIDF Similarity: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.3334\n",
      "  TFIDF Similarity: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.6797\n",
      "  TFIDF Similarity: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.1443\n",
      "  TFIDF Similarity: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "def calculate_match_score(user, job, similarity_score):\n",
    "    # Base score from TFIDF similarity\n",
    "    total_score = similarity_score * 0.6  # 60% weight for content similarity\n",
    "    \n",
    "    # Experience match (20% weight)\n",
    "    exp_score = 0.0\n",
    "    if user['experience'] >= job['required_experience']:\n",
    "        exp_score = 0.2\n",
    "    elif user['experience'] >= job['required_experience'] * 0.8:  # Allow 80% of required\n",
    "        exp_score = 0.1\n",
    "    total_score += exp_score\n",
    "    \n",
    "    # Location match (10% weight)\n",
    "    location_score = 0.1 if (user['location'] == job['location'] or \n",
    "                           (job['remote_ok'] and user['remote_ok'])) else 0.0\n",
    "    total_score += location_score\n",
    "    \n",
    "    # Education match (10% weight)\n",
    "    education_levels = {'high school': 1, 'bachelor': 2, 'master': 3, 'phd': 4}\n",
    "    user_highest_edu = max([education_levels.get(edu.split(',')[0].strip().lower(), 0) \n",
    "                          for edu in user['education']])\n",
    "    required_edu = education_levels.get(job['required_education'].lower(), 0)\n",
    "    education_score = 0.1 if user_highest_edu >= required_edu else 0.0\n",
    "    total_score += education_score\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "# Print results with combined scoring\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    # Calculate combined scores\n",
    "    user_similarities = similarities[i]\n",
    "    combined_scores = [(idx, calculate_match_score(user, job, sim_score)) \n",
    "                      for idx, (job, sim_score) in enumerate(zip(sample_jobs, user_similarities))]\n",
    "    \n",
    "    # Sort by combined score\n",
    "    top_matches = sorted(combined_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Overall Match Score: {score:.4f}\")\n",
    "        print(f\"  TFIDF Similarity: {user_similarities[job_idx]:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Required Education: {job['required_education']}\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_columns = ['title', 'description']\n",
    "df_tfidf = df[tfidf_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        123849 non-null  object\n",
      " 1   description  123842 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values in each column:\n",
      "title          0\n",
      "description    7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNull values in each column:\")\n",
    "print(df_tfidf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_tfidf.dropna(subset=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Service Technician</td>\n",
       "      <td>Looking for HVAC service tech with experience ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "1                  Mental Health Therapist/Counselor   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "4                                 Service Technician   \n",
       "\n",
       "                                         description  \n",
       "0  Job descriptionA leading real estate firm in N...  \n",
       "1  At Aspen Therapy and Wellness , we are committ...  \n",
       "2  The National Exemplar is accepting application...  \n",
       "3  Senior Associate Attorney - Elder Law / Trusts...  \n",
       "4  Looking for HVAC service tech with experience ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSample data:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\62390856.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']\n"
     ]
    }
   ],
   "source": [
    "df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample combined text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Marketing Coordinator | Job descriptionA leadi...\n",
       "1    Mental Health Therapist/Counselor | At Aspen T...\n",
       "2    Assitant Restaurant Manager | The National Exe...\n",
       "3    Senior Elder Law / Trusts and Estates Associat...\n",
       "4     Service Technician | Looking for HVAC service...\n",
       "Name: combined_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sample combined text:\")\n",
    "df_clean['combined_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test lemmatization:\n",
      "Original: Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\n",
      "Processed: marketing coordinator job description coordinate marketing campaign analyze metric work team manage project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        # POS tagging\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        \n",
    "        # Lemmatize with POS\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_tokens = []\n",
    "        for token, tag in pos_tags:\n",
    "            if tag.startswith('VB'):  # Verb\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='v')\n",
    "            elif tag.startswith('NN'):  # Noun\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='n')\n",
    "            elif tag.startswith('JJ'):  # Adjective\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='a')\n",
    "            else:\n",
    "                lem_token = lemmatizer.lemmatize(token)\n",
    "            lemmatized_tokens.append(lem_token)\n",
    "        \n",
    "        return ' '.join(lemmatized_tokens)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Test with the same text\n",
    "test_text = \"Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\"\n",
    "processed = preprocess_text(test_text)\n",
    "\n",
    "print(\"\\nTest lemmatization:\")\n",
    "print(\"Original:\", test_text)\n",
    "print(\"Processed:\", processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\1890915169.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs Processed Text:\n",
      "\n",
      "Original: Marketing Coordinator | Job descriptionA leading real estate firm in New Jersey is seeking an administrative Marketing Coordinator with some experience in graphic design. You will be working closely w ...\n",
      "Processed: marketing coordinator job descriptiona lead real estate firm new jersey seek administrative marketing coordinator experience graphic design work closely fun kind ambitious member sale team dynamic exe ...\n",
      "\n",
      "Original: Mental Health Therapist/Counselor | At Aspen Therapy and Wellness , we are committed to serving clients with best practices to help them with change, improvements and better quality of life. We believ ...\n",
      "Processed: mental health therapist counselor aspen therapy wellness commit serve client best practice help change improvement better quality life believe provide secure supportive environment grow clinician lear ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Original vs Processed Text:\")\n",
    "for orig, proc in zip(df_clean['combined_text'].head(2), df_clean['processed_text'].head(2)):\n",
    "    print(\"\\nOriginal:\", orig[:200], \"...\")\n",
    "    print(\"Processed:\", proc[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TFIDF matrix: (123842, 1000)\n",
      "\n",
      "Number of features: 1000\n",
      "\n",
      "Sample features (first 20):\n",
      "['ability' 'ability work' 'able' 'accept' 'access' 'accommodation'\n",
      " 'accord' 'accordance' 'account' 'accountability' 'accounting' 'accredit'\n",
      " 'accuracy' 'accurate' 'accurately' 'achieve' 'across' 'act' 'action'\n",
      " 'active']\n",
      "\n",
      "Sample document vector (first document):\n",
      "Non-zero terms and their TFIDF scores:\n",
      "marketing: 0.3849\n",
      "design: 0.2246\n",
      "event: 0.1816\n",
      "brand: 0.1785\n",
      "organize: 0.1768\n",
      "coordinator: 0.1630\n",
      "person: 0.1586\n",
      "request: 0.1511\n",
      "fun: 0.1494\n",
      "market: 0.1435\n"
     ]
    }
   ],
   "source": [
    "# Create TFIDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit features to most frequent 1000 terms\n",
    "    min_df=5,          # Ignore terms that appear in less than 5 documents\n",
    "    max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
    "    ngram_range=(1, 2) # Include both unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = tfidf.fit_transform(df_clean['processed_text'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Shape of TFIDF matrix: {tfidf_matrix.shape}\")\n",
    "print(f\"\\nNumber of features: {len(feature_names)}\")\n",
    "print(\"\\nSample features (first 20):\")\n",
    "print(feature_names[:20])\n",
    "\n",
    "# Show sample vector\n",
    "print(\"\\nSample document vector (first document):\")\n",
    "sample_vector = tfidf_matrix[0].toarray()[0]\n",
    "sample_terms = [(term, score) for term, score in zip(feature_names, sample_vector) if score > 0]\n",
    "print(\"Non-zero terms and their TFIDF scores:\")\n",
    "for term, score in sorted(sample_terms, key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{term}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user profiles\n",
    "sample_users = [\n",
    "    {\n",
    "        'skills': [\"Digital Marketing\", \"Brand Management\", \"Social Media\", \"Graphic Design\"],\n",
    "        'experience': 5.5,\n",
    "        'education': [\"bachelor, Marketing University\", \"master, Digital Marketing Institute\"],\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'skills': [\"Python\", \"FastAPI\", \"SQL\", \"Machine Learning\"],\n",
    "        'experience': 3.0,\n",
    "        'education': [\"bachelor, Computer Science University\"],\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sample job postings\n",
    "sample_jobs = [\n",
    "    {\n",
    "        'title': \"Senior Marketing Manager\",\n",
    "        'description': \"Looking for an experienced marketing professional to lead our digital marketing initiatives.\",\n",
    "        'required_skills': [\"Digital Marketing\", \"Brand Management\", \"Team Leadership\"],\n",
    "        'required_experience': 5.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'title': \"Python Developer\",\n",
    "        'description': \"Seeking a Python developer with experience in web frameworks and machine learning.\",\n",
    "        'required_skills': [\"Python\", \"FastAPI\", \"SQL\"],\n",
    "        'required_experience': 2.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "# Prepare text for vectorization\n",
    "def prepare_user_text(user):\n",
    "    text = ' '.join(user['skills'])\n",
    "    text += ' ' + ' '.join([edu.split(',')[0] for edu in user['education']])  # Add education levels\n",
    "    return text\n",
    "\n",
    "def prepare_job_text(job):\n",
    "    text = job['title'] + ' ' + job['description']\n",
    "    text += ' ' + ' '.join(job['required_skills'])\n",
    "    text += ' ' + job['required_education']\n",
    "    return text\n",
    "\n",
    "# Preprocess and vectorize\n",
    "user_texts = [preprocess_text(prepare_user_text(u)) for u in sample_users]\n",
    "job_texts = [preprocess_text(prepare_job_text(j)) for j in sample_jobs]\n",
    "\n",
    "# Transform texts to TFIDF vectors\n",
    "user_vectors = tfidf.transform(user_texts)\n",
    "job_vectors = tfidf.transform(job_texts)\n",
    "\n",
    "# Calculate similarity\n",
    "similarities = cosine_similarity(user_vectors, job_vectors)\n",
    "\n",
    "# Print results\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    user_similarities = similarities[i]\n",
    "    top_matches = sorted(enumerate(user_similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Similarity Score: {score:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.7379\n",
      "  TFIDF Similarity: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.3334\n",
      "  TFIDF Similarity: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.6797\n",
      "  TFIDF Similarity: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.1443\n",
      "  TFIDF Similarity: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "def calculate_match_score(user, job, similarity_score):\n",
    "    # Base score from TFIDF similarity\n",
    "    total_score = similarity_score * 0.6  # 60% weight for content similarity\n",
    "    \n",
    "    # Experience match (20% weight)\n",
    "    exp_score = 0.0\n",
    "    if user['experience'] >= job['required_experience']:\n",
    "        exp_score = 0.2\n",
    "    elif user['experience'] >= job['required_experience'] * 0.8:  # Allow 80% of required\n",
    "        exp_score = 0.1\n",
    "    total_score += exp_score\n",
    "    \n",
    "    # Location match (10% weight)\n",
    "    location_score = 0.1 if (user['location'] == job['location'] or \n",
    "                           (job['remote_ok'] and user['remote_ok'])) else 0.0\n",
    "    total_score += location_score\n",
    "    \n",
    "    # Education match (10% weight)\n",
    "    education_levels = {'high school': 1, 'bachelor': 2, 'master': 3, 'phd': 4}\n",
    "    user_highest_edu = max([education_levels.get(edu.split(',')[0].strip().lower(), 0) \n",
    "                          for edu in user['education']])\n",
    "    required_edu = education_levels.get(job['required_education'].lower(), 0)\n",
    "    education_score = 0.1 if user_highest_edu >= required_edu else 0.0\n",
    "    total_score += education_score\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "# Print results with combined scoring\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    # Calculate combined scores\n",
    "    user_similarities = similarities[i]\n",
    "    combined_scores = [(idx, calculate_match_score(user, job, sim_score)) \n",
    "                      for idx, (job, sim_score) in enumerate(zip(sample_jobs, user_similarities))]\n",
    "    \n",
    "    # Sort by combined score\n",
    "    top_matches = sorted(combined_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Overall Match Score: {score:.4f}\")\n",
    "        print(f\"  TFIDF Similarity: {user_similarities[job_idx]:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Required Education: {job['required_education']}\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  int64  \n",
      " 1   company_name                122130 non-null  object \n",
      " 2   title                       123849 non-null  object \n",
      " 3   description                 123842 non-null  object \n",
      " 4   max_salary                  29793 non-null   float64\n",
      " 5   pay_period                  36073 non-null   object \n",
      " 6   location                    123849 non-null  object \n",
      " 7   company_id                  122132 non-null  float64\n",
      " 8   views                       122160 non-null  float64\n",
      " 9   med_salary                  6280 non-null    float64\n",
      " 10  min_salary                  29793 non-null   float64\n",
      " 11  formatted_work_type         123849 non-null  object \n",
      " 12  applies                     23320 non-null   float64\n",
      " 13  original_listed_time        123849 non-null  float64\n",
      " 14  remote_allowed              15246 non-null   float64\n",
      " 15  job_posting_url             123849 non-null  object \n",
      " 16  application_url             87184 non-null   object \n",
      " 17  application_type            123849 non-null  object \n",
      " 18  expiry                      123849 non-null  float64\n",
      " 19  closed_time                 1073 non-null    float64\n",
      " 20  formatted_experience_level  94440 non-null   object \n",
      " 21  skills_desc                 2439 non-null    object \n",
      " 22  listed_time                 123849 non-null  float64\n",
      " 23  posting_domain              83881 non-null   object \n",
      " 24  sponsored                   123849 non-null  int64  \n",
      " 25  work_type                   123849 non-null  object \n",
      " 26  currency                    36073 non-null   object \n",
      " 27  compensation_type           36073 non-null   object \n",
      " 28  normalized_salary           36073 non-null   float64\n",
      " 29  zip_code                    102977 non-null  float64\n",
      " 30  fips                        96434 non-null   float64\n",
      "dtypes: float64(14), int64(2), object(15)\n",
      "memory usage: 29.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('linkedin_jobs.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  int64  \n",
      " 1   company_name                122130 non-null  object \n",
      " 2   title                       123849 non-null  object \n",
      " 3   description                 123842 non-null  object \n",
      " 4   max_salary                  29793 non-null   float64\n",
      " 5   pay_period                  36073 non-null   object \n",
      " 6   location                    123849 non-null  object \n",
      " 7   company_id                  122132 non-null  float64\n",
      " 8   views                       122160 non-null  float64\n",
      " 9   med_salary                  6280 non-null    float64\n",
      " 10  min_salary                  29793 non-null   float64\n",
      " 11  formatted_work_type         123849 non-null  object \n",
      " 12  applies                     23320 non-null   float64\n",
      " 13  original_listed_time        123849 non-null  float64\n",
      " 14  remote_allowed              15246 non-null   float64\n",
      " 15  job_posting_url             123849 non-null  object \n",
      " 16  application_url             87184 non-null   object \n",
      " 17  application_type            123849 non-null  object \n",
      " 18  expiry                      123849 non-null  float64\n",
      " 19  closed_time                 1073 non-null    float64\n",
      " 20  formatted_experience_level  94440 non-null   object \n",
      " 21  skills_desc                 2439 non-null    object \n",
      " 22  listed_time                 123849 non-null  float64\n",
      " 23  posting_domain              83881 non-null   object \n",
      " 24  sponsored                   123849 non-null  int64  \n",
      " 25  work_type                   123849 non-null  object \n",
      " 26  currency                    36073 non-null   object \n",
      " 27  compensation_type           36073 non-null   object \n",
      " 28  normalized_salary           36073 non-null   float64\n",
      " 29  zip_code                    102977 non-null  float64\n",
      " 30  fips                        96434 non-null   float64\n",
      "dtypes: float64(14), int64(2), object(15)\n",
      "memory usage: 29.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('linkedin_jobs.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_columns = ['title', 'description']\n",
    "df_tfidf = df[tfidf_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        123849 non-null  object\n",
      " 1   description  123842 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values in each column:\n",
      "title          0\n",
      "description    7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNull values in each column:\")\n",
    "print(df_tfidf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_tfidf.dropna(subset=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Service Technician</td>\n",
       "      <td>Looking for HVAC service tech with experience ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "1                  Mental Health Therapist/Counselor   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "4                                 Service Technician   \n",
       "\n",
       "                                         description  \n",
       "0  Job descriptionA leading real estate firm in N...  \n",
       "1  At Aspen Therapy and Wellness , we are committ...  \n",
       "2  The National Exemplar is accepting application...  \n",
       "3  Senior Associate Attorney - Elder Law / Trusts...  \n",
       "4  Looking for HVAC service tech with experience ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSample data:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\62390856.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']\n"
     ]
    }
   ],
   "source": [
    "df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample combined text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Marketing Coordinator | Job descriptionA leadi...\n",
       "1    Mental Health Therapist/Counselor | At Aspen T...\n",
       "2    Assitant Restaurant Manager | The National Exe...\n",
       "3    Senior Elder Law / Trusts and Estates Associat...\n",
       "4     Service Technician | Looking for HVAC service...\n",
       "Name: combined_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sample combined text:\")\n",
    "df_clean['combined_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test lemmatization:\n",
      "Original: Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\n",
      "Processed: marketing coordinator job description coordinate marketing campaign analyze metric work team manage project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        # POS tagging\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        \n",
    "        # Lemmatize with POS\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_tokens = []\n",
    "        for token, tag in pos_tags:\n",
    "            if tag.startswith('VB'):  # Verb\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='v')\n",
    "            elif tag.startswith('NN'):  # Noun\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='n')\n",
    "            elif tag.startswith('JJ'):  # Adjective\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='a')\n",
    "            else:\n",
    "                lem_token = lemmatizer.lemmatize(token)\n",
    "            lemmatized_tokens.append(lem_token)\n",
    "        \n",
    "        return ' '.join(lemmatized_tokens)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Test with the same text\n",
    "test_text = \"Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\"\n",
    "processed = preprocess_text(test_text)\n",
    "\n",
    "print(\"\\nTest lemmatization:\")\n",
    "print(\"Original:\", test_text)\n",
    "print(\"Processed:\", processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\1890915169.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs Processed Text:\n",
      "\n",
      "Original: Marketing Coordinator | Job descriptionA leading real estate firm in New Jersey is seeking an administrative Marketing Coordinator with some experience in graphic design. You will be working closely w ...\n",
      "Processed: marketing coordinator job descriptiona lead real estate firm new jersey seek administrative marketing coordinator experience graphic design work closely fun kind ambitious member sale team dynamic exe ...\n",
      "\n",
      "Original: Mental Health Therapist/Counselor | At Aspen Therapy and Wellness , we are committed to serving clients with best practices to help them with change, improvements and better quality of life. We believ ...\n",
      "Processed: mental health therapist counselor aspen therapy wellness commit serve client best practice help change improvement better quality life believe provide secure supportive environment grow clinician lear ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Original vs Processed Text:\")\n",
    "for orig, proc in zip(df_clean['combined_text'].head(2), df_clean['processed_text'].head(2)):\n",
    "    print(\"\\nOriginal:\", orig[:200], \"...\")\n",
    "    print(\"Processed:\", proc[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TFIDF matrix: (123842, 1000)\n",
      "\n",
      "Number of features: 1000\n",
      "\n",
      "Sample features (first 20):\n",
      "['ability' 'ability work' 'able' 'accept' 'access' 'accommodation'\n",
      " 'accord' 'accordance' 'account' 'accountability' 'accounting' 'accredit'\n",
      " 'accuracy' 'accurate' 'accurately' 'achieve' 'across' 'act' 'action'\n",
      " 'active']\n",
      "\n",
      "Sample document vector (first document):\n",
      "Non-zero terms and their TFIDF scores:\n",
      "marketing: 0.3849\n",
      "design: 0.2246\n",
      "event: 0.1816\n",
      "brand: 0.1785\n",
      "organize: 0.1768\n",
      "coordinator: 0.1630\n",
      "person: 0.1586\n",
      "request: 0.1511\n",
      "fun: 0.1494\n",
      "market: 0.1435\n"
     ]
    }
   ],
   "source": [
    "# Create TFIDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit features to most frequent 1000 terms\n",
    "    min_df=5,          # Ignore terms that appear in less than 5 documents\n",
    "    max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
    "    ngram_range=(1, 2) # Include both unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = tfidf.fit_transform(df_clean['processed_text'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Shape of TFIDF matrix: {tfidf_matrix.shape}\")\n",
    "print(f\"\\nNumber of features: {len(feature_names)}\")\n",
    "print(\"\\nSample features (first 20):\")\n",
    "print(feature_names[:20])\n",
    "\n",
    "# Show sample vector\n",
    "print(\"\\nSample document vector (first document):\")\n",
    "sample_vector = tfidf_matrix[0].toarray()[0]\n",
    "sample_terms = [(term, score) for term, score in zip(feature_names, sample_vector) if score > 0]\n",
    "print(\"Non-zero terms and their TFIDF scores:\")\n",
    "for term, score in sorted(sample_terms, key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{term}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user profiles\n",
    "sample_users = [\n",
    "    {\n",
    "        'skills': [\"Digital Marketing\", \"Brand Management\", \"Social Media\", \"Graphic Design\"],\n",
    "        'experience': 5.5,\n",
    "        'education': [\"bachelor, Marketing University\", \"master, Digital Marketing Institute\"],\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'skills': [\"Python\", \"FastAPI\", \"SQL\", \"Machine Learning\"],\n",
    "        'experience': 3.0,\n",
    "        'education': [\"bachelor, Computer Science University\"],\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sample job postings\n",
    "sample_jobs = [\n",
    "    {\n",
    "        'title': \"Senior Marketing Manager\",\n",
    "        'description': \"Looking for an experienced marketing professional to lead our digital marketing initiatives.\",\n",
    "        'required_skills': [\"Digital Marketing\", \"Brand Management\", \"Team Leadership\"],\n",
    "        'required_experience': 5.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'title': \"Python Developer\",\n",
    "        'description': \"Seeking a Python developer with experience in web frameworks and machine learning.\",\n",
    "        'required_skills': [\"Python\", \"FastAPI\", \"SQL\"],\n",
    "        'required_experience': 2.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "# Prepare text for vectorization\n",
    "def prepare_user_text(user):\n",
    "    text = ' '.join(user['skills'])\n",
    "    text += ' ' + ' '.join([edu.split(',')[0] for edu in user['education']])  # Add education levels\n",
    "    return text\n",
    "\n",
    "def prepare_job_text(job):\n",
    "    text = job['title'] + ' ' + job['description']\n",
    "    text += ' ' + ' '.join(job['required_skills'])\n",
    "    text += ' ' + job['required_education']\n",
    "    return text\n",
    "\n",
    "# Preprocess and vectorize\n",
    "user_texts = [preprocess_text(prepare_user_text(u)) for u in sample_users]\n",
    "job_texts = [preprocess_text(prepare_job_text(j)) for j in sample_jobs]\n",
    "\n",
    "# Transform texts to TFIDF vectors\n",
    "user_vectors = tfidf.transform(user_texts)\n",
    "job_vectors = tfidf.transform(job_texts)\n",
    "\n",
    "# Calculate similarity\n",
    "similarities = cosine_similarity(user_vectors, job_vectors)\n",
    "\n",
    "# Print results\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    user_similarities = similarities[i]\n",
    "    top_matches = sorted(enumerate(user_similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Similarity Score: {score:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.7379\n",
      "  TFIDF Similarity: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.3334\n",
      "  TFIDF Similarity: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.6797\n",
      "  TFIDF Similarity: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.1443\n",
      "  TFIDF Similarity: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "def calculate_match_score(user, job, similarity_score):\n",
    "    # Base score from TFIDF similarity\n",
    "    total_score = similarity_score * 0.6  # 60% weight for content similarity\n",
    "    \n",
    "    # Experience match (20% weight)\n",
    "    exp_score = 0.0\n",
    "    if user['experience'] >= job['required_experience']:\n",
    "        exp_score = 0.2\n",
    "    elif user['experience'] >= job['required_experience'] * 0.8:  # Allow 80% of required\n",
    "        exp_score = 0.1\n",
    "    total_score += exp_score\n",
    "    \n",
    "    # Location match (10% weight)\n",
    "    location_score = 0.1 if (user['location'] == job['location'] or \n",
    "                           (job['remote_ok'] and user['remote_ok'])) else 0.0\n",
    "    total_score += location_score\n",
    "    \n",
    "    # Education match (10% weight)\n",
    "    education_levels = {'high school': 1, 'bachelor': 2, 'master': 3, 'phd': 4}\n",
    "    user_highest_edu = max([education_levels.get(edu.split(',')[0].strip().lower(), 0) \n",
    "                          for edu in user['education']])\n",
    "    required_edu = education_levels.get(job['required_education'].lower(), 0)\n",
    "    education_score = 0.1 if user_highest_edu >= required_edu else 0.0\n",
    "    total_score += education_score\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "# Print results with combined scoring\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    # Calculate combined scores\n",
    "    user_similarities = similarities[i]\n",
    "    combined_scores = [(idx, calculate_match_score(user, job, sim_score)) \n",
    "                      for idx, (job, sim_score) in enumerate(zip(sample_jobs, user_similarities))]\n",
    "    \n",
    "    # Sort by combined score\n",
    "    top_matches = sorted(combined_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Overall Match Score: {score:.4f}\")\n",
    "        print(f\"  TFIDF Similarity: {user_similarities[job_idx]:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Required Education: {job['required_education']}\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_columns = ['title', 'description']\n",
    "df_tfidf = df[tfidf_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        123849 non-null  object\n",
      " 1   description  123842 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values in each column:\n",
      "title          0\n",
      "description    7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNull values in each column:\")\n",
    "print(df_tfidf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_tfidf.dropna(subset=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Service Technician</td>\n",
       "      <td>Looking for HVAC service tech with experience ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "1                  Mental Health Therapist/Counselor   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "4                                 Service Technician   \n",
       "\n",
       "                                         description  \n",
       "0  Job descriptionA leading real estate firm in N...  \n",
       "1  At Aspen Therapy and Wellness , we are committ...  \n",
       "2  The National Exemplar is accepting application...  \n",
       "3  Senior Associate Attorney - Elder Law / Trusts...  \n",
       "4  Looking for HVAC service tech with experience ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSample data:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\62390856.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']\n"
     ]
    }
   ],
   "source": [
    "df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample combined text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Marketing Coordinator | Job descriptionA leadi...\n",
       "1    Mental Health Therapist/Counselor | At Aspen T...\n",
       "2    Assitant Restaurant Manager | The National Exe...\n",
       "3    Senior Elder Law / Trusts and Estates Associat...\n",
       "4     Service Technician | Looking for HVAC service...\n",
       "Name: combined_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sample combined text:\")\n",
    "df_clean['combined_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test lemmatization:\n",
      "Original: Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\n",
      "Processed: marketing coordinator job description coordinate marketing campaign analyze metric work team manage project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        # POS tagging\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        \n",
    "        # Lemmatize with POS\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_tokens = []\n",
    "        for token, tag in pos_tags:\n",
    "            if tag.startswith('VB'):  # Verb\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='v')\n",
    "            elif tag.startswith('NN'):  # Noun\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='n')\n",
    "            elif tag.startswith('JJ'):  # Adjective\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='a')\n",
    "            else:\n",
    "                lem_token = lemmatizer.lemmatize(token)\n",
    "            lemmatized_tokens.append(lem_token)\n",
    "        \n",
    "        return ' '.join(lemmatized_tokens)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Test with the same text\n",
    "test_text = \"Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\"\n",
    "processed = preprocess_text(test_text)\n",
    "\n",
    "print(\"\\nTest lemmatization:\")\n",
    "print(\"Original:\", test_text)\n",
    "print(\"Processed:\", processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\1890915169.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs Processed Text:\n",
      "\n",
      "Original: Marketing Coordinator | Job descriptionA leading real estate firm in New Jersey is seeking an administrative Marketing Coordinator with some experience in graphic design. You will be working closely w ...\n",
      "Processed: marketing coordinator job descriptiona lead real estate firm new jersey seek administrative marketing coordinator experience graphic design work closely fun kind ambitious member sale team dynamic exe ...\n",
      "\n",
      "Original: Mental Health Therapist/Counselor | At Aspen Therapy and Wellness , we are committed to serving clients with best practices to help them with change, improvements and better quality of life. We believ ...\n",
      "Processed: mental health therapist counselor aspen therapy wellness commit serve client best practice help change improvement better quality life believe provide secure supportive environment grow clinician lear ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Original vs Processed Text:\")\n",
    "for orig, proc in zip(df_clean['combined_text'].head(2), df_clean['processed_text'].head(2)):\n",
    "    print(\"\\nOriginal:\", orig[:200], \"...\")\n",
    "    print(\"Processed:\", proc[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TFIDF matrix: (123842, 1000)\n",
      "\n",
      "Number of features: 1000\n",
      "\n",
      "Sample features (first 20):\n",
      "['ability' 'ability work' 'able' 'accept' 'access' 'accommodation'\n",
      " 'accord' 'accordance' 'account' 'accountability' 'accounting' 'accredit'\n",
      " 'accuracy' 'accurate' 'accurately' 'achieve' 'across' 'act' 'action'\n",
      " 'active']\n",
      "\n",
      "Sample document vector (first document):\n",
      "Non-zero terms and their TFIDF scores:\n",
      "marketing: 0.3849\n",
      "design: 0.2246\n",
      "event: 0.1816\n",
      "brand: 0.1785\n",
      "organize: 0.1768\n",
      "coordinator: 0.1630\n",
      "person: 0.1586\n",
      "request: 0.1511\n",
      "fun: 0.1494\n",
      "market: 0.1435\n"
     ]
    }
   ],
   "source": [
    "# Create TFIDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit features to most frequent 1000 terms\n",
    "    min_df=5,          # Ignore terms that appear in less than 5 documents\n",
    "    max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
    "    ngram_range=(1, 2) # Include both unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = tfidf.fit_transform(df_clean['processed_text'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Shape of TFIDF matrix: {tfidf_matrix.shape}\")\n",
    "print(f\"\\nNumber of features: {len(feature_names)}\")\n",
    "print(\"\\nSample features (first 20):\")\n",
    "print(feature_names[:20])\n",
    "\n",
    "# Show sample vector\n",
    "print(\"\\nSample document vector (first document):\")\n",
    "sample_vector = tfidf_matrix[0].toarray()[0]\n",
    "sample_terms = [(term, score) for term, score in zip(feature_names, sample_vector) if score > 0]\n",
    "print(\"Non-zero terms and their TFIDF scores:\")\n",
    "for term, score in sorted(sample_terms, key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{term}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user profiles\n",
    "sample_users = [\n",
    "    {\n",
    "        'skills': [\"Digital Marketing\", \"Brand Management\", \"Social Media\", \"Graphic Design\"],\n",
    "        'experience': 5.5,\n",
    "        'education': [\"bachelor, Marketing University\", \"master, Digital Marketing Institute\"],\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'skills': [\"Python\", \"FastAPI\", \"SQL\", \"Machine Learning\"],\n",
    "        'experience': 3.0,\n",
    "        'education': [\"bachelor, Computer Science University\"],\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sample job postings\n",
    "sample_jobs = [\n",
    "    {\n",
    "        'title': \"Senior Marketing Manager\",\n",
    "        'description': \"Looking for an experienced marketing professional to lead our digital marketing initiatives.\",\n",
    "        'required_skills': [\"Digital Marketing\", \"Brand Management\", \"Team Leadership\"],\n",
    "        'required_experience': 5.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'title': \"Python Developer\",\n",
    "        'description': \"Seeking a Python developer with experience in web frameworks and machine learning.\",\n",
    "        'required_skills': [\"Python\", \"FastAPI\", \"SQL\"],\n",
    "        'required_experience': 2.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "# Prepare text for vectorization\n",
    "def prepare_user_text(user):\n",
    "    text = ' '.join(user['skills'])\n",
    "    text += ' ' + ' '.join([edu.split(',')[0] for edu in user['education']])  # Add education levels\n",
    "    return text\n",
    "\n",
    "def prepare_job_text(job):\n",
    "    text = job['title'] + ' ' + job['description']\n",
    "    text += ' ' + ' '.join(job['required_skills'])\n",
    "    text += ' ' + job['required_education']\n",
    "    return text\n",
    "\n",
    "# Preprocess and vectorize\n",
    "user_texts = [preprocess_text(prepare_user_text(u)) for u in sample_users]\n",
    "job_texts = [preprocess_text(prepare_job_text(j)) for j in sample_jobs]\n",
    "\n",
    "# Transform texts to TFIDF vectors\n",
    "user_vectors = tfidf.transform(user_texts)\n",
    "job_vectors = tfidf.transform(job_texts)\n",
    "\n",
    "# Calculate similarity\n",
    "similarities = cosine_similarity(user_vectors, job_vectors)\n",
    "\n",
    "# Print results\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    user_similarities = similarities[i]\n",
    "    top_matches = sorted(enumerate(user_similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Similarity Score: {score:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.7379\n",
      "  TFIDF Similarity: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.3334\n",
      "  TFIDF Similarity: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.6797\n",
      "  TFIDF Similarity: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.1443\n",
      "  TFIDF Similarity: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "def calculate_match_score(user, job, similarity_score):\n",
    "    # Base score from TFIDF similarity\n",
    "    total_score = similarity_score * 0.6  # 60% weight for content similarity\n",
    "    \n",
    "    # Experience match (20% weight)\n",
    "    exp_score = 0.0\n",
    "    if user['experience'] >= job['required_experience']:\n",
    "        exp_score = 0.2\n",
    "    elif user['experience'] >= job['required_experience'] * 0.8:  # Allow 80% of required\n",
    "        exp_score = 0.1\n",
    "    total_score += exp_score\n",
    "    \n",
    "    # Location match (10% weight)\n",
    "    location_score = 0.1 if (user['location'] == job['location'] or \n",
    "                           (job['remote_ok'] and user['remote_ok'])) else 0.0\n",
    "    total_score += location_score\n",
    "    \n",
    "    # Education match (10% weight)\n",
    "    education_levels = {'high school': 1, 'bachelor': 2, 'master': 3, 'phd': 4}\n",
    "    user_highest_edu = max([education_levels.get(edu.split(',')[0].strip().lower(), 0) \n",
    "                          for edu in user['education']])\n",
    "    required_edu = education_levels.get(job['required_education'].lower(), 0)\n",
    "    education_score = 0.1 if user_highest_edu >= required_edu else 0.0\n",
    "    total_score += education_score\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "# Print results with combined scoring\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    # Calculate combined scores\n",
    "    user_similarities = similarities[i]\n",
    "    combined_scores = [(idx, calculate_match_score(user, job, sim_score)) \n",
    "                      for idx, (job, sim_score) in enumerate(zip(sample_jobs, user_similarities))]\n",
    "    \n",
    "    # Sort by combined score\n",
    "    top_matches = sorted(combined_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Overall Match Score: {score:.4f}\")\n",
    "        print(f\"  TFIDF Similarity: {user_similarities[job_idx]:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Required Education: {job['required_education']}\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  int64  \n",
      " 1   company_name                122130 non-null  object \n",
      " 2   title                       123849 non-null  object \n",
      " 3   description                 123842 non-null  object \n",
      " 4   max_salary                  29793 non-null   float64\n",
      " 5   pay_period                  36073 non-null   object \n",
      " 6   location                    123849 non-null  object \n",
      " 7   company_id                  122132 non-null  float64\n",
      " 8   views                       122160 non-null  float64\n",
      " 9   med_salary                  6280 non-null    float64\n",
      " 10  min_salary                  29793 non-null   float64\n",
      " 11  formatted_work_type         123849 non-null  object \n",
      " 12  applies                     23320 non-null   float64\n",
      " 13  original_listed_time        123849 non-null  float64\n",
      " 14  remote_allowed              15246 non-null   float64\n",
      " 15  job_posting_url             123849 non-null  object \n",
      " 16  application_url             87184 non-null   object \n",
      " 17  application_type            123849 non-null  object \n",
      " 18  expiry                      123849 non-null  float64\n",
      " 19  closed_time                 1073 non-null    float64\n",
      " 20  formatted_experience_level  94440 non-null   object \n",
      " 21  skills_desc                 2439 non-null    object \n",
      " 22  listed_time                 123849 non-null  float64\n",
      " 23  posting_domain              83881 non-null   object \n",
      " 24  sponsored                   123849 non-null  int64  \n",
      " 25  work_type                   123849 non-null  object \n",
      " 26  currency                    36073 non-null   object \n",
      " 27  compensation_type           36073 non-null   object \n",
      " 28  normalized_salary           36073 non-null   float64\n",
      " 29  zip_code                    102977 non-null  float64\n",
      " 30  fips                        96434 non-null   float64\n",
      "dtypes: float64(14), int64(2), object(15)\n",
      "memory usage: 29.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('linkedin_jobs.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  int64  \n",
      " 1   company_name                122130 non-null  object \n",
      " 2   title                       123849 non-null  object \n",
      " 3   description                 123842 non-null  object \n",
      " 4   max_salary                  29793 non-null   float64\n",
      " 5   pay_period                  36073 non-null   object \n",
      " 6   location                    123849 non-null  object \n",
      " 7   company_id                  122132 non-null  float64\n",
      " 8   views                       122160 non-null  float64\n",
      " 9   med_salary                  6280 non-null    float64\n",
      " 10  min_salary                  29793 non-null   float64\n",
      " 11  formatted_work_type         123849 non-null  object \n",
      " 12  applies                     23320 non-null   float64\n",
      " 13  original_listed_time        123849 non-null  float64\n",
      " 14  remote_allowed              15246 non-null   float64\n",
      " 15  job_posting_url             123849 non-null  object \n",
      " 16  application_url             87184 non-null   object \n",
      " 17  application_type            123849 non-null  object \n",
      " 18  expiry                      123849 non-null  float64\n",
      " 19  closed_time                 1073 non-null    float64\n",
      " 20  formatted_experience_level  94440 non-null   object \n",
      " 21  skills_desc                 2439 non-null    object \n",
      " 22  listed_time                 123849 non-null  float64\n",
      " 23  posting_domain              83881 non-null   object \n",
      " 24  sponsored                   123849 non-null  int64  \n",
      " 25  work_type                   123849 non-null  object \n",
      " 26  currency                    36073 non-null   object \n",
      " 27  compensation_type           36073 non-null   object \n",
      " 28  normalized_salary           36073 non-null   float64\n",
      " 29  zip_code                    102977 non-null  float64\n",
      " 30  fips                        96434 non-null   float64\n",
      "dtypes: float64(14), int64(2), object(15)\n",
      "memory usage: 29.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('linkedin_jobs.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_columns = ['title', 'description']\n",
    "df_tfidf = df[tfidf_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        123849 non-null  object\n",
      " 1   description  123842 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values in each column:\n",
      "title          0\n",
      "description    7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNull values in each column:\")\n",
    "print(df_tfidf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_tfidf.dropna(subset=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Service Technician</td>\n",
       "      <td>Looking for HVAC service tech with experience ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "1                  Mental Health Therapist/Counselor   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "4                                 Service Technician   \n",
       "\n",
       "                                         description  \n",
       "0  Job descriptionA leading real estate firm in N...  \n",
       "1  At Aspen Therapy and Wellness , we are committ...  \n",
       "2  The National Exemplar is accepting application...  \n",
       "3  Senior Associate Attorney - Elder Law / Trusts...  \n",
       "4  Looking for HVAC service tech with experience ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSample data:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\62390856.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']\n"
     ]
    }
   ],
   "source": [
    "df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample combined text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Marketing Coordinator | Job descriptionA leadi...\n",
       "1    Mental Health Therapist/Counselor | At Aspen T...\n",
       "2    Assitant Restaurant Manager | The National Exe...\n",
       "3    Senior Elder Law / Trusts and Estates Associat...\n",
       "4     Service Technician | Looking for HVAC service...\n",
       "Name: combined_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sample combined text:\")\n",
    "df_clean['combined_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test lemmatization:\n",
      "Original: Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\n",
      "Processed: marketing coordinator job description coordinate marketing campaign analyze metric work team manage project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        # POS tagging\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        \n",
    "        # Lemmatize with POS\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_tokens = []\n",
    "        for token, tag in pos_tags:\n",
    "            if tag.startswith('VB'):  # Verb\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='v')\n",
    "            elif tag.startswith('NN'):  # Noun\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='n')\n",
    "            elif tag.startswith('JJ'):  # Adjective\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='a')\n",
    "            else:\n",
    "                lem_token = lemmatizer.lemmatize(token)\n",
    "            lemmatized_tokens.append(lem_token)\n",
    "        \n",
    "        return ' '.join(lemmatized_tokens)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Test with the same text\n",
    "test_text = \"Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\"\n",
    "processed = preprocess_text(test_text)\n",
    "\n",
    "print(\"\\nTest lemmatization:\")\n",
    "print(\"Original:\", test_text)\n",
    "print(\"Processed:\", processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\1890915169.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs Processed Text:\n",
      "\n",
      "Original: Marketing Coordinator | Job descriptionA leading real estate firm in New Jersey is seeking an administrative Marketing Coordinator with some experience in graphic design. You will be working closely w ...\n",
      "Processed: marketing coordinator job descriptiona lead real estate firm new jersey seek administrative marketing coordinator experience graphic design work closely fun kind ambitious member sale team dynamic exe ...\n",
      "\n",
      "Original: Mental Health Therapist/Counselor | At Aspen Therapy and Wellness , we are committed to serving clients with best practices to help them with change, improvements and better quality of life. We believ ...\n",
      "Processed: mental health therapist counselor aspen therapy wellness commit serve client best practice help change improvement better quality life believe provide secure supportive environment grow clinician lear ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Original vs Processed Text:\")\n",
    "for orig, proc in zip(df_clean['combined_text'].head(2), df_clean['processed_text'].head(2)):\n",
    "    print(\"\\nOriginal:\", orig[:200], \"...\")\n",
    "    print(\"Processed:\", proc[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TFIDF matrix: (123842, 1000)\n",
      "\n",
      "Number of features: 1000\n",
      "\n",
      "Sample features (first 20):\n",
      "['ability' 'ability work' 'able' 'accept' 'access' 'accommodation'\n",
      " 'accord' 'accordance' 'account' 'accountability' 'accounting' 'accredit'\n",
      " 'accuracy' 'accurate' 'accurately' 'achieve' 'across' 'act' 'action'\n",
      " 'active']\n",
      "\n",
      "Sample document vector (first document):\n",
      "Non-zero terms and their TFIDF scores:\n",
      "marketing: 0.3849\n",
      "design: 0.2246\n",
      "event: 0.1816\n",
      "brand: 0.1785\n",
      "organize: 0.1768\n",
      "coordinator: 0.1630\n",
      "person: 0.1586\n",
      "request: 0.1511\n",
      "fun: 0.1494\n",
      "market: 0.1435\n"
     ]
    }
   ],
   "source": [
    "# Create TFIDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit features to most frequent 1000 terms\n",
    "    min_df=5,          # Ignore terms that appear in less than 5 documents\n",
    "    max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
    "    ngram_range=(1, 2) # Include both unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = tfidf.fit_transform(df_clean['processed_text'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Shape of TFIDF matrix: {tfidf_matrix.shape}\")\n",
    "print(f\"\\nNumber of features: {len(feature_names)}\")\n",
    "print(\"\\nSample features (first 20):\")\n",
    "print(feature_names[:20])\n",
    "\n",
    "# Show sample vector\n",
    "print(\"\\nSample document vector (first document):\")\n",
    "sample_vector = tfidf_matrix[0].toarray()[0]\n",
    "sample_terms = [(term, score) for term, score in zip(feature_names, sample_vector) if score > 0]\n",
    "print(\"Non-zero terms and their TFIDF scores:\")\n",
    "for term, score in sorted(sample_terms, key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{term}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user profiles\n",
    "sample_users = [\n",
    "    {\n",
    "        'skills': [\"Digital Marketing\", \"Brand Management\", \"Social Media\", \"Graphic Design\"],\n",
    "        'experience': 5.5,\n",
    "        'education': [\"bachelor, Marketing University\", \"master, Digital Marketing Institute\"],\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'skills': [\"Python\", \"FastAPI\", \"SQL\", \"Machine Learning\"],\n",
    "        'experience': 3.0,\n",
    "        'education': [\"bachelor, Computer Science University\"],\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sample job postings\n",
    "sample_jobs = [\n",
    "    {\n",
    "        'title': \"Senior Marketing Manager\",\n",
    "        'description': \"Looking for an experienced marketing professional to lead our digital marketing initiatives.\",\n",
    "        'required_skills': [\"Digital Marketing\", \"Brand Management\", \"Team Leadership\"],\n",
    "        'required_experience': 5.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'title': \"Python Developer\",\n",
    "        'description': \"Seeking a Python developer with experience in web frameworks and machine learning.\",\n",
    "        'required_skills': [\"Python\", \"FastAPI\", \"SQL\"],\n",
    "        'required_experience': 2.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "# Prepare text for vectorization\n",
    "def prepare_user_text(user):\n",
    "    text = ' '.join(user['skills'])\n",
    "    text += ' ' + ' '.join([edu.split(',')[0] for edu in user['education']])  # Add education levels\n",
    "    return text\n",
    "\n",
    "def prepare_job_text(job):\n",
    "    text = job['title'] + ' ' + job['description']\n",
    "    text += ' ' + ' '.join(job['required_skills'])\n",
    "    text += ' ' + job['required_education']\n",
    "    return text\n",
    "\n",
    "# Preprocess and vectorize\n",
    "user_texts = [preprocess_text(prepare_user_text(u)) for u in sample_users]\n",
    "job_texts = [preprocess_text(prepare_job_text(j)) for j in sample_jobs]\n",
    "\n",
    "# Transform texts to TFIDF vectors\n",
    "user_vectors = tfidf.transform(user_texts)\n",
    "job_vectors = tfidf.transform(job_texts)\n",
    "\n",
    "# Calculate similarity\n",
    "similarities = cosine_similarity(user_vectors, job_vectors)\n",
    "\n",
    "# Print results\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    user_similarities = similarities[i]\n",
    "    top_matches = sorted(enumerate(user_similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Similarity Score: {score:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.7379\n",
      "  TFIDF Similarity: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.3334\n",
      "  TFIDF Similarity: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.6797\n",
      "  TFIDF Similarity: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.1443\n",
      "  TFIDF Similarity: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "def calculate_match_score(user, job, similarity_score):\n",
    "    # Base score from TFIDF similarity\n",
    "    total_score = similarity_score * 0.6  # 60% weight for content similarity\n",
    "    \n",
    "    # Experience match (20% weight)\n",
    "    exp_score = 0.0\n",
    "    if user['experience'] >= job['required_experience']:\n",
    "        exp_score = 0.2\n",
    "    elif user['experience'] >= job['required_experience'] * 0.8:  # Allow 80% of required\n",
    "        exp_score = 0.1\n",
    "    total_score += exp_score\n",
    "    \n",
    "    # Location match (10% weight)\n",
    "    location_score = 0.1 if (user['location'] == job['location'] or \n",
    "                           (job['remote_ok'] and user['remote_ok'])) else 0.0\n",
    "    total_score += location_score\n",
    "    \n",
    "    # Education match (10% weight)\n",
    "    education_levels = {'high school': 1, 'bachelor': 2, 'master': 3, 'phd': 4}\n",
    "    user_highest_edu = max([education_levels.get(edu.split(',')[0].strip().lower(), 0) \n",
    "                          for edu in user['education']])\n",
    "    required_edu = education_levels.get(job['required_education'].lower(), 0)\n",
    "    education_score = 0.1 if user_highest_edu >= required_edu else 0.0\n",
    "    total_score += education_score\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "# Print results with combined scoring\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    # Calculate combined scores\n",
    "    user_similarities = similarities[i]\n",
    "    combined_scores = [(idx, calculate_match_score(user, job, sim_score)) \n",
    "                      for idx, (job, sim_score) in enumerate(zip(sample_jobs, user_similarities))]\n",
    "    \n",
    "    # Sort by combined score\n",
    "    top_matches = sorted(combined_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Overall Match Score: {score:.4f}\")\n",
    "        print(f\"  TFIDF Similarity: {user_similarities[job_idx]:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Required Education: {job['required_education']}\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_columns = ['title', 'description']\n",
    "df_tfidf = df[tfidf_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        123849 non-null  object\n",
      " 1   description  123842 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values in each column:\n",
      "title          0\n",
      "description    7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNull values in each column:\")\n",
    "print(df_tfidf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_tfidf.dropna(subset=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Service Technician</td>\n",
       "      <td>Looking for HVAC service tech with experience ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "1                  Mental Health Therapist/Counselor   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "4                                 Service Technician   \n",
       "\n",
       "                                         description  \n",
       "0  Job descriptionA leading real estate firm in N...  \n",
       "1  At Aspen Therapy and Wellness , we are committ...  \n",
       "2  The National Exemplar is accepting application...  \n",
       "3  Senior Associate Attorney - Elder Law / Trusts...  \n",
       "4  Looking for HVAC service tech with experience ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nSample data:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\62390856.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']\n"
     ]
    }
   ],
   "source": [
    "df_clean['combined_text'] = df_clean['title'] + ' | ' + df_clean['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample combined text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Marketing Coordinator | Job descriptionA leadi...\n",
       "1    Mental Health Therapist/Counselor | At Aspen T...\n",
       "2    Assitant Restaurant Manager | The National Exe...\n",
       "3    Senior Elder Law / Trusts and Estates Associat...\n",
       "4     Service Technician | Looking for HVAC service...\n",
       "Name: combined_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample combined text:\")\n",
    "df_clean['combined_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test lemmatization:\n",
      "Original: Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\n",
      "Processed: marketing coordinator job description coordinate marketing campaign analyze metric work team manage project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akstrov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        # POS tagging\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        \n",
    "        # Lemmatize with POS\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_tokens = []\n",
    "        for token, tag in pos_tags:\n",
    "            if tag.startswith('VB'):  # Verb\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='v')\n",
    "            elif tag.startswith('NN'):  # Noun\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='n')\n",
    "            elif tag.startswith('JJ'):  # Adjective\n",
    "                lem_token = lemmatizer.lemmatize(token, pos='a')\n",
    "            else:\n",
    "                lem_token = lemmatizer.lemmatize(token)\n",
    "            lemmatized_tokens.append(lem_token)\n",
    "        \n",
    "        return ' '.join(lemmatized_tokens)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Test with the same text\n",
    "test_text = \"Marketing Coordinator | Job description: coordinating marketing campaigns, analyzing metrics, working with teams, managing projects\"\n",
    "processed = preprocess_text(test_text)\n",
    "\n",
    "print(\"\\nTest lemmatization:\")\n",
    "print(\"Original:\", test_text)\n",
    "print(\"Processed:\", processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akstrov\\AppData\\Local\\Temp\\ipykernel_16128\\1890915169.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "df_clean['processed_text'] = df_clean['combined_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs Processed Text:\n",
      "\n",
      "Original: Marketing Coordinator | Job descriptionA leading real estate firm in New Jersey is seeking an administrative Marketing Coordinator with some experience in graphic design. You will be working closely w ...\n",
      "Processed: marketing coordinator job descriptiona lead real estate firm new jersey seek administrative marketing coordinator experience graphic design work closely fun kind ambitious member sale team dynamic exe ...\n",
      "\n",
      "Original: Mental Health Therapist/Counselor | At Aspen Therapy and Wellness , we are committed to serving clients with best practices to help them with change, improvements and better quality of life. We believ ...\n",
      "Processed: mental health therapist counselor aspen therapy wellness commit serve client best practice help change improvement better quality life believe provide secure supportive environment grow clinician lear ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Original vs Processed Text:\")\n",
    "for orig, proc in zip(df_clean['combined_text'].head(2), df_clean['processed_text'].head(2)):\n",
    "    print(\"\\nOriginal:\", orig[:200], \"...\")\n",
    "    print(\"Processed:\", proc[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TFIDF matrix: (123842, 1000)\n",
      "\n",
      "Number of features: 1000\n",
      "\n",
      "Sample features (first 20):\n",
      "['ability' 'ability work' 'able' 'accept' 'access' 'accommodation'\n",
      " 'accord' 'accordance' 'account' 'accountability' 'accounting' 'accredit'\n",
      " 'accuracy' 'accurate' 'accurately' 'achieve' 'across' 'act' 'action'\n",
      " 'active']\n",
      "\n",
      "Sample document vector (first document):\n",
      "Non-zero terms and their TFIDF scores:\n",
      "marketing: 0.3849\n",
      "design: 0.2246\n",
      "event: 0.1816\n",
      "brand: 0.1785\n",
      "organize: 0.1768\n",
      "coordinator: 0.1630\n",
      "person: 0.1586\n",
      "request: 0.1511\n",
      "fun: 0.1494\n",
      "market: 0.1435\n"
     ]
    }
   ],
   "source": [
    "# Create TFIDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit features to most frequent 1000 terms\n",
    "    min_df=5,          # Ignore terms that appear in less than 5 documents\n",
    "    max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
    "    ngram_range=(1, 2) # Include both unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = tfidf.fit_transform(df_clean['processed_text'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Shape of TFIDF matrix: {tfidf_matrix.shape}\")\n",
    "print(f\"\\nNumber of features: {len(feature_names)}\")\n",
    "print(\"\\nSample features (first 20):\")\n",
    "print(feature_names[:20])\n",
    "\n",
    "# Show sample vector\n",
    "print(\"\\nSample document vector (first document):\")\n",
    "sample_vector = tfidf_matrix[0].toarray()[0]\n",
    "sample_terms = [(term, score) for term, score in zip(feature_names, sample_vector) if score > 0]\n",
    "print(\"Non-zero terms and their TFIDF scores:\")\n",
    "for term, score in sorted(sample_terms, key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{term}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user profiles\n",
    "sample_users = [\n",
    "    {\n",
    "        'skills': [\"Digital Marketing\", \"Brand Management\", \"Social Media\", \"Graphic Design\"],\n",
    "        'experience': 5.5,\n",
    "        'education': [\"bachelor, Marketing University\", \"master, Digital Marketing Institute\"],\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'skills': [\"Python\", \"FastAPI\", \"SQL\", \"Machine Learning\"],\n",
    "        'experience': 3.0,\n",
    "        'education': [\"bachelor, Computer Science University\"],\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sample job postings\n",
    "sample_jobs = [\n",
    "    {\n",
    "        'title': \"Senior Marketing Manager\",\n",
    "        'description': \"Looking for an experienced marketing professional to lead our digital marketing initiatives.\",\n",
    "        'required_skills': [\"Digital Marketing\", \"Brand Management\", \"Team Leadership\"],\n",
    "        'required_experience': 5.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"New York, USA\",\n",
    "        'remote_ok': True\n",
    "    },\n",
    "    {\n",
    "        'title': \"Python Developer\",\n",
    "        'description': \"Seeking a Python developer with experience in web frameworks and machine learning.\",\n",
    "        'required_skills': [\"Python\", \"FastAPI\", \"SQL\"],\n",
    "        'required_experience': 2.0,\n",
    "        'required_education': \"bachelor\",\n",
    "        'location': \"San Francisco, USA\",\n",
    "        'remote_ok': False\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Similarity Score: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Similarity Score: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "# Prepare text for vectorization\n",
    "def prepare_user_text(user):\n",
    "    text = ' '.join(user['skills'])\n",
    "    text += ' ' + ' '.join([edu.split(',')[0] for edu in user['education']])  # Add education levels\n",
    "    return text\n",
    "\n",
    "def prepare_job_text(job):\n",
    "    text = job['title'] + ' ' + job['description']\n",
    "    text += ' ' + ' '.join(job['required_skills'])\n",
    "    text += ' ' + job['required_education']\n",
    "    return text\n",
    "\n",
    "# Preprocess and vectorize\n",
    "user_texts = [preprocess_text(prepare_user_text(u)) for u in sample_users]\n",
    "job_texts = [preprocess_text(prepare_job_text(j)) for j in sample_jobs]\n",
    "\n",
    "# Transform texts to TFIDF vectors\n",
    "user_vectors = tfidf.transform(user_texts)\n",
    "job_vectors = tfidf.transform(job_texts)\n",
    "\n",
    "# Calculate similarity\n",
    "similarities = cosine_similarity(user_vectors, job_vectors)\n",
    "\n",
    "# Print results\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    user_similarities = similarities[i]\n",
    "    top_matches = sorted(enumerate(user_similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Similarity Score: {score:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Skills: ['Digital Marketing', 'Brand Management', 'Social Media', 'Graphic Design']\n",
      "Experience: 5.5 years\n",
      "Education: ['bachelor, Marketing University', 'master, Digital Marketing Institute']\n",
      "Location: New York, USA\n",
      "Top job matches:\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.7379\n",
      "  TFIDF Similarity: 0.5632\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.3334\n",
      "  TFIDF Similarity: 0.0556\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "User 2\n",
      "Skills: ['Python', 'FastAPI', 'SQL', 'Machine Learning']\n",
      "Experience: 3.0 years\n",
      "Education: ['bachelor, Computer Science University']\n",
      "Location: San Francisco, USA\n",
      "Top job matches:\n",
      "\n",
      "- Python Developer\n",
      "  Overall Match Score: 0.6797\n",
      "  TFIDF Similarity: 0.4662\n",
      "  Required Experience: 2.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: San Francisco, USA\n",
      "  Remote: False\n",
      "\n",
      "- Senior Marketing Manager\n",
      "  Overall Match Score: 0.1443\n",
      "  TFIDF Similarity: 0.0738\n",
      "  Required Experience: 5.0 years\n",
      "  Required Education: bachelor\n",
      "  Location: New York, USA\n",
      "  Remote: True\n"
     ]
    }
   ],
   "source": [
    "def calculate_match_score(user, job, similarity_score):\n",
    "    # Base score from TFIDF similarity\n",
    "    total_score = similarity_score * 0.6  # 60% weight for content similarity\n",
    "    \n",
    "    # Experience match (20% weight)\n",
    "    exp_score = 0.0\n",
    "    if user['experience'] >= job['required_experience']:\n",
    "        exp_score = 0.2\n",
    "    elif user['experience'] >= job['required_experience'] * 0.8:  # Allow 80% of required\n",
    "        exp_score = 0.1\n",
    "    total_score += exp_score\n",
    "    \n",
    "    # Location match (10% weight)\n",
    "    location_score = 0.1 if (user['location'] == job['location'] or \n",
    "                           (job['remote_ok'] and user['remote_ok'])) else 0.0\n",
    "    total_score += location_score\n",
    "    \n",
    "    # Education match (10% weight)\n",
    "    education_levels = {'high school': 1, 'bachelor': 2, 'master': 3, 'phd': 4}\n",
    "    user_highest_edu = max([education_levels.get(edu.split(',')[0].strip().lower(), 0) \n",
    "                          for edu in user['education']])\n",
    "    required_edu = education_levels.get(job['required_education'].lower(), 0)\n",
    "    education_score = 0.1 if user_highest_edu >= required_edu else 0.0\n",
    "    total_score += education_score\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "# Print results with combined scoring\n",
    "for i, user in enumerate(sample_users):\n",
    "    print(f\"\\nUser {i+1}\")\n",
    "    print(f\"Skills: {user['skills']}\")\n",
    "    print(f\"Experience: {user['experience']} years\")\n",
    "    print(f\"Education: {user['education']}\")\n",
    "    print(f\"Location: {user['location']}\")\n",
    "    print(\"Top job matches:\")\n",
    "    \n",
    "    # Calculate combined scores\n",
    "    user_similarities = similarities[i]\n",
    "    combined_scores = [(idx, calculate_match_score(user, job, sim_score)) \n",
    "                      for idx, (job, sim_score) in enumerate(zip(sample_jobs, user_similarities))]\n",
    "    \n",
    "    # Sort by combined score\n",
    "    top_matches = sorted(combined_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for job_idx, score in top_matches:\n",
    "        job = sample_jobs[job_idx]\n",
    "        print(f\"\\n- {job['title']}\")\n",
    "        print(f\"  Overall Match Score: {score:.4f}\")\n",
    "        print(f\"  TFIDF Similarity: {user_similarities[job_idx]:.4f}\")\n",
    "        print(f\"  Required Experience: {job['required_experience']} years\")\n",
    "        print(f\"  Required Education: {job['required_education']}\")\n",
    "        print(f\"  Location: {job['location']}\")\n",
    "        print(f\"  Remote: {job['remote_ok']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
